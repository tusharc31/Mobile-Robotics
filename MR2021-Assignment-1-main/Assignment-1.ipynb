{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "056d1f43",
   "metadata": {},
   "source": [
    "# Assignment-1: Transformations and representations\n",
    "\n",
    "Team Name: Bhagwaan Bharose\n",
    "\n",
    "Roll number: 2019111019, 2019111026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e278237",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "- Code must be written in Python in Jupyter Notebooks. We highly recommend using anaconda distribution or at the minimum, virtual environments for this assignment. See `Set Up` for detailed step-by-step instructions about the installation setup.\n",
    "- Save all your results in ```results/<question_number>/<sub_topic_number>/```\n",
    "- The **References** section provides you with important resources to solve the assignment.\n",
    "- For this assignment, you will be using Open3D extensively. Refer to [Open3D Documentation](http://www.open3d.org/docs/release/): you can use the in-built methods and **unless explicitly mentioned**, don't need to code from scratch for this assignment. \n",
    "- Make sure your code is modular since you may need to reuse parts for future assignments.\n",
    "- Answer the descriptive questions in your own words with context & clarity. Do not copy answers from online resources or lecture notes.\n",
    "- The **deadline** for this assignment is on 11/09/2021 at 11:55pm. Please note that there will be no extensions.\n",
    "- Plagiarism is **strictly prohibited**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba455b2",
   "metadata": {},
   "source": [
    "# Submission Instructions\n",
    "\n",
    "1. Make sure your code runs without any errors after reinitializing the kernel and removing all saved variables.\n",
    "2. After completing your code and saving your results, zip the folder with name as ``Team_<team_name>_MR2021_Assignment_<assignment_number>.zip``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256a8041",
   "metadata": {},
   "source": [
    "# Set Up\n",
    "\n",
    "We highly recommend using anaconda distribution or at the minimum, virtual environments for this assignment. All assignments will be python based, hence familiarising yourself with Python is essential.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2626c87b",
   "metadata": {},
   "source": [
    "## Setting up Anaconda environment (Recommended)\n",
    "\n",
    "1. Install Anaconda or Miniconda from [here](https://docs.conda.io/projects/conda/en/latest/user-guide/install/linux.html) depending on your requirements.\n",
    "2. Now simply run `conda env create -f environment.yml` in the current folder to create an environment `mr_assignment1` (`environment.yml` can be found in `misc/`).\n",
    "3. Activate it using `conda activate mr_assignment1`.\n",
    "\n",
    "## Setting up Virtual environment using venv\n",
    "\n",
    "You can also set up a virtual environment using venv\n",
    "\n",
    "1. Run `sudo apt-get install python3-venv` from command line.\n",
    "2. `python3 -m venv ~/virtual_env/mr_assignment1`. (you can set the environment path to anything)\n",
    "3. `source ~/virtual_env/mr_assignment1/bin/activate`\n",
    "4. `pip3 install -r requirements.txt` from the current folder (`requirements.txt` can be found in `misc/`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfbe683f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937a4b4b",
   "metadata": {},
   "source": [
    "# 1. Getting started with Open3D\n",
    "\n",
    "Open3D is an open-source library that deals with 3D data, such as point clouds, mesh. We'll be using Open3D frequently as we work with point clouds. Let's start with something simple:\n",
    "\n",
    "<img src=\"misc/bunny.jpg\" alt=\"drawing\" width=\"200\"/>\n",
    "\n",
    "1. Read the Stanford Bunny file (in `data/`) given to you and visualise it using Open3D.\n",
    "2. Convert the mesh to a point cloud and change the colour of points.\n",
    "3. Set a predefined viewing angle (using Open3D) for visualization and display the axes while plotting.\n",
    "4. Scale, Transform, and Rotate the rabbit (visualise after each step).\n",
    "5. Save the point cloud as bunny.pcd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d4700b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 1 - Read the Stanford Bunny file (in data/) given to you and visualise it using Open3D.\n",
    "mesh = o3d.io.read_triangle_mesh(\"./data/bunny.ply\")\n",
    "o3d.visualization.draw_geometries([mesh])\n",
    "mesh.compute_vertex_normals()\n",
    "o3d.visualization.draw_geometries([mesh])\n",
    "\n",
    "# Part 2 - Convert the mesh to a point cloud and change the colour of points.\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = mesh.vertices\n",
    "pcd.colors = mesh.vertex_colors\n",
    "pcd.normals = mesh.vertex_normals\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "pcd.paint_uniform_color([1, 0, 0])\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "# Part 3 - Set a predefined viewing angle (using Open3D) for visualization and display the axes while plotting.\n",
    "FOR = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.025, origin=[0,0,0])\n",
    "o3d.visualization.draw_geometries([pcd, FOR], \n",
    "                                  zoom=1, \n",
    "                                  front=[-0.01, 0.01, 0], \n",
    "                                  lookat=[-0.01, 0.01, 0],\n",
    "                                  up=[0,1,0]\n",
    "                                 )\n",
    "\n",
    "# Part 4 - Scale, Transform, and Rotate the rabbit (visualise after each step).\n",
    "\n",
    "#Scale\n",
    "pcd.scale(1.5, center=pcd.get_center())\n",
    "o3d.visualization.draw_geometries([pcd, FOR], \n",
    "                                  zoom=1, \n",
    "                                  front=[-0.01, 0.01, 0], \n",
    "                                  lookat=[-0.01, 0.01, 0],\n",
    "                                  up=[0,1,0]\n",
    "                                 )\n",
    "# Transform\n",
    "T = np.eye(4)\n",
    "T[:3, :3] = pcd.get_rotation_matrix_from_xyz((0, np.pi / 3, np.pi / 2))\n",
    "T[0, 3] = 0.1\n",
    "T[1, 3] = 0.1\n",
    "pcd = pcd.transform(T)\n",
    "o3d.visualization.draw_geometries([pcd, FOR], \n",
    "                                  zoom=1, \n",
    "                                  front=[-0.01, 0.01, 0], \n",
    "                                  lookat=[-0.01, 0.01, 0],\n",
    "                                  up=[0,1,0]\n",
    "                                 )\n",
    "# Rotate\n",
    "R = pcd.get_rotation_matrix_from_xyz((np.pi/2, 0, 0))\n",
    "pcd.rotate(R, center=(0, 0, 0))\n",
    "o3d.visualization.draw_geometries([pcd, FOR])\n",
    "\n",
    "# Part 5 - Save the point cloud as bunny.pcd.\n",
    "o3d.io.write_point_cloud(\"./results/1/5/bunny.pcd\", pcd) # result is being \"./results/1/5/bunny.pcd\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aca334a",
   "metadata": {},
   "source": [
    "# 2. Transformations and representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c14f0d",
   "metadata": {},
   "source": [
    "## a) Euler angles\n",
    "1. Write a function that returns a rotation matrix given the angles $\\alpha$, $\\beta$, and $\\gamma$ in radians (X-Y-Z)\n",
    "\n",
    "2. Solve for angles using ```fsolve from scipy``` for three initializations of your choice and compare.\n",
    "$$M(\\alpha , \\beta ,\\gamma)=\\left[\\begin{array}{rrr}0.26200263 & -0.19674724 & 0.944799 \\\\0.21984631 & 0.96542533 & 0.14007684 \\\\\n",
    "    -0.93969262 & 0.17101007 & 0.29619813\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "$$N(\\alpha , \\beta ,\\gamma)=\\left[\\begin{array}{rrr}0 & -0.173648178 &  0.984807753 \\\\0 & 0.984807753 & 0.173648178 \\\\\n",
    "    -1 & 0 & 0\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "3. What is a Gimbal lock? \n",
    "\n",
    "4. Show an example where a Gimbal lock occurs and visualize the Gimbal lock on the given bunny point cloud. You have to show the above by **animation** (cube rotating along each axis one by one).\n",
    "    - *Hint: Use Open3D's non-blocking visualization and discretize the rotation to simulate the animation. For example, if you want to rotate by $30^{\\circ}$ around a particular axis, do in increments of $5^{\\circ}$ 6 times to make it look like an animation.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1077cd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R =  [[ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [-1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def rotation_matrix(theta):\n",
    "    R_x = np.array([[1, 0, 0],\n",
    "                    [0, math.cos(theta[0]), -math.sin(theta[0])],\n",
    "                    [0, math.sin(theta[0]), math.cos(theta[0])]\n",
    "                   ])\n",
    "    R_y = np.array([[math.cos(theta[1]), 0, math.sin(theta[1])],\n",
    "                    [0, 1, 0],\n",
    "                    [-math.sin(theta[1]), 0, math.cos(theta[1])]\n",
    "                    ])\n",
    "    R_z = np.array([[math.cos(theta[2]), -math.sin(theta[2]), 0],\n",
    "                    [math.sin(theta[2]), math.cos(theta[2]), 0],\n",
    "                    [0, 0, 1]\n",
    "                    ])\n",
    "    gg = np.dot(np.dot(R_x,R_y), R_z)\n",
    "    return gg.round(15) # Remove `.round(15)` to get exact calculation done by numpy \n",
    "\n",
    "#Set the angles here\n",
    "alpha=0\n",
    "beta=np.pi/2\n",
    "gamma=0\n",
    "\n",
    "R=rotation_matrix([alpha, beta, gamma])\n",
    "print(\"R = \", R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8bfe8a",
   "metadata": {},
   "source": [
    "Here, if A represents the fixed frame and B represents the rotating frame then the first rotation happens about X<sub>B</sub> by α, then about Y<sub>B</sub> by β, and finally about Z<sub>B</sub> by γ. In the above output, the rotation matrix is parameterized by X-Y-Z Euler angles will be indicated by the notation <sup>A</sup>R<sub>B</sub> <sub>XYZ</sub> (α, β, γ). \n",
    "Thinking of the rotations as descriptions of these frames, we can immediately write <sup>A</sup>R<sub>B</sub> = <sup>A</sup>R<sub>B1</sub> * <sup>B1</sup>R<sub>B2</sub> * <sup>B2</sup>R<sub>B3</sub>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "145ebd16",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Angles for matrix M (in radians):\n",
      "[2.69092136 1.24081926 0.6525376 ]\n",
      "[2.69482461 1.23915393 0.64884598]\n",
      "[2.71033706 1.23232451 0.63419604]\n",
      "\n",
      "Angles for matrix N (in radians):\n",
      "[1.54064068 1.39618562 1.6004937 ]\n",
      "[1.57227972 1.39626321 1.56933547]\n",
      "[1.22823297 1.38573419 1.90794697]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import fsolve\n",
    "\n",
    "def rotation_equations(thetas):\n",
    "    ca=np.cos(thetas[0])\n",
    "    cb=np.cos(thetas[1])\n",
    "    cc=np.cos(thetas[2])\n",
    "    sa=np.sin(thetas[0])\n",
    "    sb=np.sin(thetas[1])\n",
    "    sc=np.sin(thetas[2])\n",
    "    return [\n",
    "        -cb*sc - Mat[0][1],\n",
    "        -sa*sb*sc+ca*cc - Mat[1][1],\n",
    "        ca*sb*sc+sa*cc - Mat[2][1]\n",
    "    ]\n",
    "\n",
    "M=[[0.26200263,-0.19674724,0.944799],\n",
    "[0.21984631,0.96542533,0.14007684],\n",
    "[-0.93969262,0.17101007,0.29619813]]\n",
    "\n",
    "N=[[0,-0.173648178,0.984807753],\n",
    "[0,0.984807753,0.1736448178],\n",
    "[-1,0,0]]\n",
    "\n",
    "# Solving angles for matrix M using different initialisations\n",
    "print(\"\\nAngles for matrix M (in radians):\")\n",
    "Mat = np.array(M)\n",
    "x = fsolve(rotation_equations, [-0.45,1.25,0.65])\n",
    "print((x%np.pi))\n",
    "x = fsolve(rotation_equations, [5.88,7.52,6.95])\n",
    "print((x%np.pi))\n",
    "x = fsolve(rotation_equations, [5.85, 1.24, 0.64])\n",
    "print((x%np.pi))\n",
    "\n",
    "# Solving angles for matrix M using different initialisations\n",
    "print(\"\\nAngles for matrix N (in radians):\")\n",
    "Mat = np.array(N)\n",
    "x = fsolve(rotation_equations, [-1.6,1.4,1.6])\n",
    "print((x%np.pi))\n",
    "x = fsolve(rotation_equations, [-1.57,1.4,1.57]) # can guess 1.57 due to structure of the matrix\n",
    "print((x%np.pi))\n",
    "x = fsolve(rotation_equations, [-1.57, 1.3, 1.57])\n",
    "print((x%np.pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d882acb4",
   "metadata": {},
   "source": [
    "After choosing 3 initializations to get almost equal values, we can now take average of these angles and generate rotation matrices for them to see how close we are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e05fc293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix M:\n",
      " [[ 0.26144617 -0.19677674  0.94494699]\n",
      " [-0.21976879 -0.96542005 -0.14023486]\n",
      " [ 0.93986573 -0.17100599 -0.29565076]]\n",
      "\n",
      "Matrix N:\n",
      " [[-2.15202677e-02 -1.75816937e-01  9.84187626e-01]\n",
      " [ 3.85591372e-03 -9.84422879e-01 -1.75774649e-01]\n",
      " [ 9.99760976e-01  1.22250487e-05  2.18629789e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Checking for M\n",
    "angles1 = np.array([2.69092136, 1.24081926, 0.6525376 ])\n",
    "angles2 = np.array([2.69482461, 1.23915393, 0.64884598])\n",
    "angles3 = np.array([2.71033706, 1.23232451, 0.63419604])\n",
    "angles = (angles1+angles2+angles3)/3\n",
    "print(\"\\nMatrix M:\\n\",rotation_matrix(angles))\n",
    "\n",
    "# Checking for N\n",
    "angles1 = np.array([1.54064068, 1.39618562, 1.6004937 ])\n",
    "angles2 = np.array([1.57227972, 1.39626321, 1.56933547])\n",
    "angles3 = np.array([1.22823297, 1.38573419, 1.90794697])\n",
    "angles = (angles1+angles2+angles3)/3\n",
    "print(\"\\nMatrix N:\\n\",rotation_matrix(angles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3226e0c3",
   "metadata": {},
   "source": [
    "As we can see up on comparing with the original values, the matrices we have obtained are roughly equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ad347",
   "metadata": {},
   "source": [
    "**What is a Gimbal lock?** \n",
    "\n",
    "Gimbal lock is a state that we may reach while performing rotation using Euler angles, purely because how we mathematically paramaterised our rotations. Let the angles during X-Y-Z Euler angle rotation be θ<sub>x</sub>, θ<sub>y</sub> and θ<sub>z</sub>, then we may reach a state where there is no way to rotate around one of the 3 axis (that is, loss of one degree of freedom).\n",
    "\n",
    "For example in X-Y-Z euler angle rotation, if θ<sub>y</sub> is set as π/2, then no matter how we adjust θ<sub>x</sub> and θ<sub>z</sub>, we are locked into a single axis of rotation. The rotation matrix after putting θ<sub>y</sub> = π/2 is shown below:\n",
    "\n",
    "<img src=\"H2.png\" alt=\"drawing\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288be32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing gimbal lock by example on bunny point cloud\n",
    "\n",
    "#Getting the bunny\n",
    "mesh = o3d.io.read_triangle_mesh(\"./data/bunny.ply\")\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = mesh.vertices\n",
    "pcd.colors = mesh.vertex_colors\n",
    "pcd.normals = mesh.vertex_normals\n",
    "pcd.paint_uniform_color([1, 0, 0])\n",
    "\n",
    "# Example of gimbal lock has already been mentioned earlier, if we rotate about Y axis by pi/2\n",
    "# then we will be stuck in an axis and rotation about X and Z won't matter.\n",
    "\n",
    "# Plotting the basic point cloud once and then shiting it to origin for easier rotation visualizaion\n",
    "FOR = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0,0,0])\n",
    "pcd = pcd.translate((0.02675991, -0.09521606, -0.00894711))\n",
    "R = pcd.get_rotation_matrix_from_xyz((0, np.pi, 0))\n",
    "pcd.rotate(R, center=(0, 0, 0))\n",
    "R = pcd.get_rotation_matrix_from_xyz((np.pi/2, 0, 0))\n",
    "pcd.rotate(R, center=(0, 0, 0))\n",
    "o3d.visualization.draw_geometries([pcd, FOR], \n",
    "                                  zoom=1, \n",
    "                                  front=[0.01, 0, 0], \n",
    "                                  lookat=[0.01, 0, 0],\n",
    "                                  up=[0,0,1]\n",
    "                                 )\n",
    "\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "\n",
    "def euler_rot(theta):\n",
    "    \n",
    "    global vis\n",
    "    vis.clear_geometries()\n",
    "    \n",
    "    source = pcd\n",
    "    target = FOR\n",
    "#     source = source_raw.voxel_down_sample(voxel_size=0.001)\n",
    "#     target = target_raw.voxel_down_sample(voxel_size=0.001)\n",
    "\n",
    "    R = pcd.get_rotation_matrix_from_xyz((theta[0], theta[1], theta[2]))\n",
    "    pcd.rotate(R, center=(0, 0, 0))\n",
    "#     vis = o3d.visualization.Visualizer()\n",
    "#     vis = o3d.visualization.draw_geometries([pcd, FOR], \n",
    "#                                       zoom=1, \n",
    "#                                       front=[0.01, 0, 0], \n",
    "#                                       lookat=[0.01, 0, 0],\n",
    "#                                       up=[0,0,1]\n",
    "#                                      )\n",
    "#     vis.create_window()\n",
    "    vis.add_geometry(source)\n",
    "    vis.add_geometry(target)\n",
    "#     for i in range(5):\n",
    "#         vis.clear_geometries()\n",
    "    vis.update_geometry(source)\n",
    "    vis.update_geometry(target)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "    \n",
    "########################################################################    \n",
    "# Showing one iteration for Gimbal lock example\n",
    "for i in range(100):\n",
    "    euler_rot([np.pi/2/100, 0, 0])\n",
    "# vis.destroy_window()\n",
    "\n",
    "for i in range(100):\n",
    "    euler_rot([0, 0, np.pi/2/100])\n",
    "# vis.destroy_window()\n",
    "\n",
    "for i in range(100):\n",
    "    euler_rot([0, np.pi/2/100, 0])\n",
    "vis.destroy_window()\n",
    "o3d.visualization.draw_geometries([pcd, FOR])\n",
    "\n",
    "########################################################################\n",
    "# # Showing another iteration for Gimbal lock example\n",
    "# pcd = o3d.geometry.PointCloud()\n",
    "# pcd.points = mesh.vertices\n",
    "# pcd.colors = mesh.vertex_colors\n",
    "# pcd.normals = mesh.vertex_normals\n",
    "# pcd.paint_uniform_color([1, 0, 0])\n",
    "# pcd = pcd.translate((0.02675991, -0.09521606, -0.00894711))\n",
    "# R = pcd.get_rotation_matrix_from_xyz((0, np.pi, 0))\n",
    "# pcd.rotate(R, center=(0, 0, 0))\n",
    "# R = pcd.get_rotation_matrix_from_xyz((np.pi/2, 0, 0))\n",
    "# pcd.rotate(R, center=(0, 0, 0))\n",
    "\n",
    "# for i in range(6):\n",
    "#     euler_rot([np.pi/6, 0, 0])\n",
    "# for i in range(6):\n",
    "#     euler_rot([0, -np.pi/2/6, 0])\n",
    "# for i in range(6):\n",
    "#     euler_rot([np.pi/2/6, 0, 0])\n",
    "\n",
    "########################################################################  \n",
    "# # Showing another iteration for Gimbal lock example\n",
    "# pcd = o3d.geometry.PointCloud()\n",
    "# pcd.points = mesh.vertices\n",
    "# pcd.colors = mesh.vertex_colors\n",
    "# pcd.normals = mesh.vertex_normals\n",
    "# pcd.paint_uniform_color([1, 0, 0])\n",
    "# pcd = pcd.translate((0.02675991, -0.09521606, -0.00894711))\n",
    "# R = pcd.get_rotation_matrix_from_xyz((0, np.pi, 0))\n",
    "# pcd.rotate(R, center=(0, 0, 0))\n",
    "# R = pcd.get_rotation_matrix_from_xyz((np.pi/2, 0, 0))\n",
    "# pcd.rotate(R, center=(0, 0, 0))\n",
    "   \n",
    "# for i in range(6):\n",
    "#     euler_rot([0, 0, 0])\n",
    "# for i in range(6):\n",
    "#     euler_rot([0, -np.pi/2/6, 0])\n",
    "# for i in range(6):\n",
    "#     euler_rot([np.pi/2/6, 0, 0])\n",
    "    \n",
    "########################################################################\n",
    "\n",
    "# import time\n",
    "# time.sleep(2)\n",
    "# def euler_rot(theta):\n",
    "#     R = pcd.get_rotation_matrix_from_xyz((theta[0], theta[1], theta[2]))\n",
    "#     pcd.rotate(R, center=(0, 0, 0))\n",
    "#     o3d.visualization.draw_geometries([pcd, FOR], \n",
    "#                                       zoom=1, \n",
    "#                                       front=[0.01, 0, 0], \n",
    "#                                       lookat=[0.01, 0, 0],\n",
    "#                                       up=[0,0,1]\n",
    "#                                      )  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d7235a",
   "metadata": {},
   "source": [
    "**Example**  \n",
    "Example of gimbal lock has already been mentioned earlier, if we rotate about Y axis by pi/2 then we will be stuck in an axis and rotation about X and Z won't matter.\n",
    "\n",
    "**Visualizing this example in the bunny animation**  \n",
    "If noticed carefully, in the final orientations of all the iterations, it is seen that the bunny always faces the +ve or -ve y-axis, so if the bunny is cut in a plane parallel to his front and back, that plane will always be parallel to the X-Z plane, which shows the loss in one degree of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c945f84a",
   "metadata": {},
   "source": [
    "## b) Quaternions\n",
    "\n",
    "1. What makes Quaternions popular in graphics? \n",
    "2. Convert a rotation matrix to quaternion and vice versa. Do not use inbuilt libraries for this question.\n",
    "3. Perform matrix multiplication of two $\\mathcal{R}_{3 \\times 3}$ rotation matrices and perform the same transformation in the quaternion space. Verify if the final transformation obtained in both the cases are the same.\n",
    "4. Try to interpolate any 3D model (cube / bunny / not sphere obviously!!) between two rotation matrices and visualize!\n",
    "\n",
    "The above questions require you to **code your own functions** and **only verify** using inbuilt functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a1b3e",
   "metadata": {},
   "source": [
    "**Answers**  \n",
    "  \n",
    "1. Quaternions are popular in graphics because:\n",
    "* They don't have the problem of Gimbal lock which is present in the case of Euler angles because of the way we mathematically paramaterise our equations.\n",
    "* They are a nice way to think about transformations, easy to code as well as debug.\n",
    "* They have mild computation benefits (sometimes), so we have reduced computation and don't involve trigonometry.\n",
    "* Fluency with quaternions can help lead into deeper/novel solutions to problems (for instance - surface parameterization and texture mapping).\n",
    "* They help make interpolating rotations easy to compute and visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dce04608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation matrix = \n",
      " [[ 0.       -0.999698  0.      ]\n",
      " [ 0.999698  0.        0.      ]\n",
      " [ 0.        0.        0.999698]]\n"
     ]
    }
   ],
   "source": [
    "# Converting quaternion to rotation matrix\n",
    "\n",
    "def quaternion_to_rotm(q):\n",
    "    \n",
    "    m=[[0,0,0], [0,0,0], [0,0,0]]\n",
    "    \n",
    "    m[0][0] = q[0]**2 + q[1]**2 - q[2]**2 - q[3]**2\n",
    "    m[0][1] = 2 * (q[1]*q[2] - q[0]*q[3])\n",
    "    m[0][2] = 2 * (q[0]*q[2] + q[1]*q[3])\n",
    "    m[1][0] = 2 * (q[0]*q[3] + q[1]*q[2])\n",
    "    m[1][1] = q[0]**2 - q[1]**2 + q[2]**2 - q[3]**2\n",
    "    m[1][2] = 2 * (q[2]*q[3] - q[0]*q[1])\n",
    "    m[2][0] = 2 * (q[1]*q[3] - q[0]*q[2])\n",
    "    m[2][1] = 2 * (q[0]*q[1] + q[2]*q[3])\n",
    "    m[2][2] = q[0]**2 - q[1]**2 - q[2]**2 + q[3]**2\n",
    "    \n",
    "    return m\n",
    "    \n",
    "# Set quaternion here\n",
    "q = [0.707,0,0,0.707]\n",
    "print(\"Rotation matrix = \\n\", np.array(quaternion_to_rotm(q)))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee16a6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quaternions = \n",
      " [0.70710678 0.         0.         0.70710678]\n"
     ]
    }
   ],
   "source": [
    "# Converting rotation matrix to quaternion\n",
    "\n",
    "def rotm_to_quaternion(mat):\n",
    "    \n",
    "    q = [0,0,0,0]\n",
    "    q[0] = np.sqrt((np.trace(mat)+1)/4) \n",
    "    q[1] = np.sqrt(mat[0][0]/2 + (1-np.trace(mat))/4) \n",
    "    q[2] = np.sqrt(mat[1][1]/2 + (1-np.trace(mat))/4)\n",
    "    q[3] = np.sqrt(mat[2][2]/2 + (1-np.trace(mat))/4)\n",
    "\n",
    "    return q\n",
    "    \n",
    "# Set rotation matrix here\n",
    "mat = [[0,-1,0],[1,0,0],[0,0,1]]\n",
    "print(\"Quaternions = \\n\", np.array(rotm_to_quaternion(np.array(mat))))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "51336b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Point after rotation using rotation matrix:\n",
      " [0.       0.999698 0.      ]\n",
      "\n",
      "Point after rotation using quaternion:\n",
      " [0.0, 0.9999999966439369, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Perform matrix multiplication of two 3×3 rotation matrices and perform the same transformation \n",
    "# in the quaternion space. Verify if the final transformation obtained in both the cases are the same.\n",
    "\n",
    "def conjugate(q):\n",
    "    return [q[0], -q[1], -q[2], -q[3]]\n",
    "\n",
    "def multiply_q(q, p):\n",
    "    res=[0,0,0,0]\n",
    "    res[0] = q[0]*p[0] - q[1]*p[1] - q[2]*p[2] - q[3]*p[3]\n",
    "    res[1] = q[0]*p[1] + q[1]*p[0] + q[2]*p[3] - q[3]*p[2]\n",
    "    res[2] = q[0]*p[2] + q[2]*p[0] - q[1]*p[3] + q[3]*p[1]\n",
    "    res[3] = q[0]*p[3] + q[3]*p[0] + q[1]*p[2] - q[2]*p[1]\n",
    "    return res\n",
    "\n",
    "# Set parameters here\n",
    "q = [0.70710678, 0., 0. ,0.70710678]\n",
    "mat = [[0., -0.999698, 0.], [0.999698, 0., 0.], [ 0., 0., 0.999698]]\n",
    "pnt = [1,0,0]\n",
    "\n",
    "q_con = conjugate(q)\n",
    "mat=np.array(mat)\n",
    "aug_pnt = [0]+pnt\n",
    "pnt = np.array(pnt)\n",
    "\n",
    "print(\"\\nPoint after rotation using rotation matrix:\\n\",np.dot(mat,pnt))\n",
    "\n",
    "res=multiply_q(multiply_q(q, aug_pnt), q_con)\n",
    "res.pop(0)\n",
    "print(\"\\nPoint after rotation using quaternion:\\n\",res) # Performing the rotation using quaternions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbb3b2e",
   "metadata": {},
   "source": [
    "We can see that the points above match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "85dbabf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_arrow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28177/3771719084.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_magnitude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mRz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_zy_rotation_for_arrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_arrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m# Create the arrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_arrow' is not defined"
     ]
    }
   ],
   "source": [
    "# Try to interpolate any 3D model (cube / bunny / not sphere obviously!!) between \n",
    "# two rotation matrices and visualize!\n",
    "\n",
    "FOR = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.025, origin=[0,0,0])\n",
    "\n",
    "q_start = [0.70710678, 0., 0. ,0.70710678]\n",
    "# q_end = \n",
    "\n",
    "scale = 10\n",
    "Ry = Rz = np.eye(3)\n",
    "end=None\n",
    "vec=None\n",
    "T = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "T[:3, -1] = [0,0,0]\n",
    "if end is not None:\n",
    "    vec = np.array(end) - np.array([0,0,0])\n",
    "elif vec is not None:\n",
    "    vec = np.array(vec)\n",
    "if end is not None or vec is not None:\n",
    "    scale = vector_magnitude(vec)\n",
    "    Rz, Ry = calculate_zy_rotation_for_arrow(vec)\n",
    "mesh = create_arrow(scale)\n",
    "# Create the arrow\n",
    "mesh.rotate(Ry, center=np.array([0, 0, 0]))\n",
    "mesh.rotate(Rz, center=np.array([0, 0, 0]))\n",
    "mesh.translate(origin)\n",
    "draw_geometries([mesh])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a8e9c",
   "metadata": {},
   "source": [
    "## c) Exponential maps (Bonus)\n",
    "\n",
    "1. What is the idea behind exponential map representation of rotation matrices?\n",
    "2. Perform matrix exponentiation and obtain the rotation matrix to rotate a vector $P$ around $\\omega$ for $\\theta$ seconds.\n",
    "$$\n",
    "\\omega = \\begin{bmatrix}2 \\\\ 1 \\\\ 15 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta = 4.1364\n",
    "$$\n",
    "\n",
    "3. Compute the logarithmic map (SO(3) to so(3)) of the rotation matrix to obtain the rotation vector and the angle of rotation\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0.1 &  -0.9487 & 0.3 \\\\\n",
    "0.9487 & 0.  & -0.3162 \\\\\n",
    "0.3   &  0.3162  & 0.9 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "You can use inbuilt libraries **only to verify** your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a2b89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f82f74d",
   "metadata": {},
   "source": [
    "# 3. Data representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44066a25",
   "metadata": {},
   "source": [
    "## a) Octomaps\n",
    "\n",
    "1. Why is an Octomap memory efficient?\n",
    "2. When do we update an Octomap and why?\n",
    "3. When would you likely use an octomap instead of a point cloud?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24e4d2a",
   "metadata": {},
   "source": [
    "**Answers**  \n",
    "  \n",
    "1. An octomap uses an octree data structure to store the occupancy probabilities. Octree is a hierarchial data structure for spatial subdivisions in 3 dimensions. Each node in an octree represents the space contained in  a cubic volume, usually called a voxel. Each voxel can recursively be subdivided into 8 smaller voxels till the minimum size is reached. This approach is memory efficient compared to point cloud approach as instead of dividing the entire volume into individual cells, **we divide a cell further only if we have any conflict**. Hence, if we know for a huge volume that it is unoccupied, we may not further divide it. This helps us save memory, since in the case of point cloud, we would have stored the occupancy probability of each point cloud within that volume.  \n",
    "<br></br>  \n",
    "2. Octomap are **built incrementally**. As the robot moves around, we get occupancy probabilities from different camera locations (get new measurements) in a local map. We then first transform this data from local map to global space and then stitch the information by updating the octomap. The update is done using the recursive method (multiplying occupancy probabilities and multiplying non-occupancy probabilities obtained from different measurements and normalizing the results to get the occupancy and non-occupancy probabilities).   \n",
    "Octomap is updated because:  \n",
    "1) After each measurement, as we update the octomap, we progressively become more confident that a cell is occupied or unoccupied with more certainity (not talking about dynamic obstacles).  \n",
    "2) A robot can collect data only for a limited range (local space). Updating the octomap helps us to helps fit the data from local space to global map so as the robot moves around, we have a bigger picture (occupancy probabilities) of the entire global map.  \n",
    "<br></br>\n",
    "3. If we don't want sematic understanding of the scene (sensing and identifying the objects/obstacles in the scene) and **can work with the information whether a volume is occupied or unaoccpied**, then we can use octomaps (as it doesn't replicate the same scene in its understanding but only measures the occupancy probabilities of the voxels). Also we will use an octomap instead of a point cloud when we want the system to be **memory efficient and the access time is not a problem** for us. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43402a9c",
   "metadata": {},
   "source": [
    "## b) Signed Distance Functions\n",
    "\n",
    "1. How do we determine object surfaces using SDF?\n",
    "2. How do we aggregate views from multiple cameras? (just a general overview is fine)\n",
    "3. Which preserves details better? Voxels or SDF? Why?\n",
    "4. What’s an advantage of SDF over a point cloud?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cf9040",
   "metadata": {},
   "source": [
    "**Answers**  \n",
    "1. In case of SDF, instead of storing probability of occupancy of a voxel, here we try to represent the distance to the surface. For each voxel, we try estimating how far it is from the surface. After applying SDF to each voxel, if the sign is negative, the voxel lies outside the surface, if the value is zero, it lies on the surface and if it is positive then it lies inside the surface. So **if SDF for a voxel is 0, it means that it represents the object's surface**. Also, since we have the distance as well for each voxel, **after some linear calculation we can find out the surface of the object mathematically** (diagram below). \n",
    "<img src=\"H1.jpg\" alt=\"drawing\" width=\"600\"/>\n",
    "<br></br>  \n",
    "2. Similar to octomaps, after we have one measurement, we need to fuse the values from the next measurements, This is done using a weighted average of the measurements. For each voxel, we have a distance (D) and weight (W) with is initially 0. Now each measurement for a voxel will have a distance (d) and weight (w) associated to it. Now values for a voxel are updated as:  \n",
    "* $D=\\frac{DW+dw}{W+w}$   \n",
    "* W=W+w  \n",
    "Updating stategies can differ from implementation to implementation. As we keep on aggregating views from multiple cameras, W keeps on increasing and hence we will get more confident (since this means we have more measurements). So we can use the value of W as confidence.\n",
    "<br></br>  \n",
    "3. SDF should preserve details better as during fusing different measurements, here we can take a custom weighted approach (that is, weighing strategy depends on implementation). Precise weighing based on confidence of measurement can help us presearve details better. So we can give higher weights to positions we are sure of getting good measurement and low weight to positions where consifdence of measurement is low. On the other hand, during fusing occupancy probabilities in voxels, all measurements get equal weightage in the recursive formula. Hence good and bad measurements influence the answer equally. Also, in SDF we are able to capture more information compared to occupancy probability of voxel.   \n",
    "<br></br>  \n",
    "4. Advantages of SDF over point clouds are:\n",
    "* SDF gives us 2 values, weights and distance to the surface wheres point clouds only store occupancy probability. Hence in SDF we can tell the confidence of a voxel, its position (inside, on or outside the surface) and its distance from the surface where as in point cloud we can only tell the occupancy probability.\n",
    "* Memory usage is high in point clouds, where as high compression can be done in SDF as voxels nearer to the surface are stored (truncated).\n",
    "* The distance value we get during SDF can be used for trajectory generation, which we can't in point clouds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a79fd1",
   "metadata": {},
   "source": [
    "# References and Resources\n",
    "\n",
    "1. Gimbal locks and quaternions: https://youtu.be/YF5ZUlKxSgE\n",
    "2. Exponential map: \n",
    "    1. 3 Blue 1 Brown: https://youtu.be/O85OWBJ2ayo\n",
    "    2. Northwestern Robotics: https://youtu.be/v_KBHaG0mas\n",
    "3. Bunny ply is taken from: http://graphics.im.ntu.edu.tw/~robin/courses/cg03/model/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
